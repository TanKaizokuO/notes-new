---
tags:
  - main
---

---
## Core LLM Categories

### ðŸ§± Base Models
**Raw pretrained models.**
* Trained on large corpora.
* No alignment or instruction tuning.
* **Best for**: Custom fine-tuning.

**Examples**:
* GPT base
* LLaMA base

**Use when**: Building specialized pipelines or performing research.

---

### ðŸ’¬ Chat Models
**Instruction-tuned + RLHF aligned.**
* Follow natural language prompts.
* Safer + more conversational.
* **Optimized for**: Assistants.

**Examples**:
* ChatGPT
* Claude
* Gemini Chat

**Use when**: Building apps, assistants, or agents.

---

### ðŸ§  Reasoning Models
**Optimized for multi-step logic.**
* Explicit chain-of-thought.
* Slower but more accurate.
* **Strong at**: Math, coding, planning.

**Examples**:
* GPT-5 Reasoning
* Claude Opus Reasoning

**Use when**: Handling complex workflows or tool orchestration.

---

## Mental Model
`Base` â†’ `Chat` â†’ `Reasoning`
*(raw â†’ aligned â†’ deliberate)*

---

**See also**:
[[Frontier Models]]  
[[Agentic AI]]
