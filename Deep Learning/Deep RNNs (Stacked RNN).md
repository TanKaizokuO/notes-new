---
tags:
  - main
---
---

For complex sequence tasks, we stack multiple RNN layers.

---

## Key Idea
Multiple layers increase representational power.

**Blocks can be**:
* Vanilla RNN
* [[GRU (Gated Recurrent Unit)]]
* [[LSTM (Long Short-Term Memory)]]

Deep versions of:
* [[Bidirectional RNN (BRNN)]] are also common.