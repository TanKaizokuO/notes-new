
"smart_sources:Transformers/Multi-Head Attention.md": {"path":"Transformers/Multi-Head Attention.md","embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06083841,-0.00300765,0.03305532,-0.01586036,-0.10819991,0.00706023,0.03945746,0.00356335,0.05157302,0.02061118,-0.00929489,-0.06457637,0.02721187,0.06930441,0.08630708,0.02686922,-0.04586684,0.00870962,-0.06412126,-0.04054232,0.10070132,0.00184227,0.01282398,-0.00647761,0.0469269,0.03192141,-0.00743534,-0.08058272,-0.02996682,-0.23544058,0.01923521,0.0610484,0.03920332,0.01457635,-0.06892782,-0.00575535,-0.02120808,0.01211632,0.02019493,0.03385351,0.01025164,0.0391486,-0.0068227,-0.03797213,-0.0947681,-0.02352392,-0.11371176,-0.02276852,-0.0599594,-0.06811107,0.00387917,-0.06971076,0.01764729,0.0108116,0.04182848,0.04993811,0.00960796,0.01396623,0.03662361,0.0095995,0.04332805,0.06787141,-0.15033562,0.0989008,0.06175708,-0.00230146,-0.07963833,-0.01753057,-0.01180523,0.10695991,-0.02442241,-0.0406705,-0.03325301,-0.02847261,0.02107085,-0.00785714,-0.01844482,0.01083311,0.03528231,-0.00872933,0.00752774,0.00579475,-0.06211494,-0.05146563,-0.00094078,0.06812024,-0.04298109,-0.05613097,-0.01656249,-0.02889363,-0.03684276,-0.06241532,0.02919773,-0.0185209,0.02243995,0.00198929,0.06037836,0.00614758,-0.06640109,0.09851529,-0.01566734,-0.06795632,0.04744442,-0.05638095,0.0186109,-0.01416359,0.02458092,-0.02822209,-0.01905945,0.04253238,0.03489141,-0.05073865,0.01295802,-0.05950252,0.0409256,0.03334608,0.02075824,0.02806387,0.06799044,-0.07710056,0.02241553,0.00885175,0.07626557,-0.02417566,0.00478778,-0.00955417,0.05826294,0.06518563,0.0187962,-0.01979498,0.08422392,-0.00385371,-0.04253211,-0.03210349,-0.01604911,-0.01315061,0.0317625,-0.01054146,0.02874233,0.02983995,0.01141789,-0.04395832,0.02378996,-0.08686019,-0.00384944,0.14422601,-0.01522937,-0.01792384,-0.06174024,-0.00518321,-0.06656778,0.04515506,0.00660643,-0.01673346,0.02700097,0.00028627,0.04211358,-0.02113369,-0.07642318,0.04007113,-0.02561551,0.00027347,-0.07729647,0.05651569,0.02302976,-0.07670318,0.01769471,0.00133335,-0.022794,-0.05352281,0.04315335,0.03066324,-0.03037539,0.02400247,0.03555558,0.01954593,-0.10743953,0.00455797,-0.02184988,-0.00739979,0.07704285,-0.04413087,-0.02674986,-0.00647234,0.00037811,-0.01320925,-0.02715485,-0.01687153,-0.02060089,0.04283525,-0.08120435,0.02732567,0.03757764,0.03506641,-0.06233468,0.0260189,0.00109386,-0.03415819,0.03456161,-0.00728161,-0.02720635,-0.04962885,-0.02568935,-0.00101568,0.00375381,0.01847214,0.00174609,0.00936609,0.06237982,0.03791074,-0.07000171,0.01100452,0.0406533,-0.02484116,-0.03591754,-0.03346645,0.0004601,0.05543252,-0.00785208,0.03316475,0.01406258,-0.08513225,-0.04965261,-0.22861288,-0.05070265,0.01150632,-0.02764325,0.07146766,-0.04030269,0.0492749,0.02646209,-0.03107077,0.08107249,0.10934015,-0.00797028,-0.09953898,-0.04161711,-0.03587437,0.05455703,0.00925022,0.03932011,-0.05332747,-0.01909996,0.05816578,0.05064411,0.02185241,-0.09903866,0.02154667,-0.04491044,0.15938978,0.06214329,0.03838667,0.08662307,0.03226182,0.04282362,-0.01718671,-0.01287631,0.01437673,-0.01425998,0.01353042,-0.02690207,0.01574222,-0.00323992,-0.04868922,-0.0271489,-0.01314485,-0.04138683,0.00524625,0.02598905,-0.02434022,-0.01521971,0.02646471,0.02518241,0.04598809,-0.09633269,-0.0186771,0.0355396,-0.00638849,-0.01930642,-0.09650122,-0.02863162,-0.05512987,0.00578155,0.01576317,0.00856073,0.03838579,-0.03576587,0.03049967,0.06684201,-0.0314819,0.01587267,-0.03544613,0.02501294,-0.02827099,0.11418347,0.04953959,0.01511728,-0.02319997,-0.02368368,0.06297258,0.00088242,-0.04061415,0.04311993,0.02535395,-0.07820731,0.01594391,0.03135898,0.06014886,-0.01297436,0.01911813,-0.04921539,0.0633334,-0.05157135,-0.01416871,-0.01384096,0.01301085,0.01963345,0.03344344,-0.02718014,-0.2796272,0.00700326,0.06819844,0.02906718,-0.05496636,0.07436414,0.01662158,-0.0351511,0.01250683,-0.01535192,-0.04077504,0.05751137,0.05498036,0.0145321,-0.01941736,0.0443911,0.01338861,0.0009382,0.03912205,0.01034948,-0.00561147,-0.00315484,0.19522822,-0.02152512,0.04984092,-0.06063073,-0.0128365,0.01859237,0.04910176,0.02379574,-0.00031704,0.02773637,0.06861869,-0.10767725,0.04743013,0.04907124,0.00133631,-0.00271218,0.06368411,0.03694407,0.00605858,0.0358416,-0.0070777,-0.05701946,0.12735671,-0.00603009,-0.00695917,-0.0197021,-0.07166341,0.01259658,-0.00976554,0.02721633,0.02207158,0.05589205,0.0707463,0.03346893,0.04425532,0.03198818,-0.04574397,-0.00573392,0.02473662,-0.01639158,-0.00952973,0.02622256,0.03353658],"last_embed":{"hash":"hr6m8j","tokens":448}}},"last_read":{"hash":"hr6m8j","at":1770290020354},"class_name":"SmartSource","last_import":{"mtime":1769774585704,"size":2768,"at":1770289976260,"hash":"hr6m8j"},"blocks":{"#---frontmatter---":[1,4],"#":[6,17],"##1. Why Multiple Heads?":[18,30],"##1. Why Multiple Heads?#{1}":[19,22],"##1. Why Multiple Heads?#{2}":[23,23],"##1. Why Multiple Heads?#{3}":[24,24],"##1. Why Multiple Heads?#{4}":[25,26],"##1. Why Multiple Heads?#{5}":[27,30],"##2. The Math of Multi-Head Attention":[31,57],"##2. The Math of Multi-Head Attention#{1}":[32,33],"##2. The Math of Multi-Head Attention#Step A: Split and Project":[34,41],"##2. The Math of Multi-Head Attention#Step A: Split and Project#{1}":[35,38],"##2. The Math of Multi-Head Attention#Step A: Split and Project#{2}":[39,39],"##2. The Math of Multi-Head Attention#Step A: Split and Project#{3}":[40,41],"##2. The Math of Multi-Head Attention#Step B: Parallel Attention":[42,46],"##2. The Math of Multi-Head Attention#Step B: Parallel Attention#{1}":[43,44],"##2. The Math of Multi-Head Attention#Step B: Parallel Attention#{2}":[45,46],"##2. The Math of Multi-Head Attention#Step C: Concatenate":[47,51],"##2. The Math of Multi-Head Attention#Step C: Concatenate#{1}":[48,49],"##2. The Math of Multi-Head Attention#Step C: Concatenate#{2}":[50,51],"##2. The Math of Multi-Head Attention#Step D: Final Linear Projection":[52,57],"##2. The Math of Multi-Head Attention#Step D: Final Linear Projection#{1}":[53,57],"##Summary":[58,67],"##Summary#{1}":[59,59],"##Summary#{2}":[60,60],"##Summary#{3}":[61,61],"##Summary#{4}":[62,63],"##Summary#{5}":[64,64],"##Summary#{6}":[65,65],"##Summary#{7}":[66,67]},"outlinks":[{"title":"Scaled Dot-Product Attention","target":"Attention","line":43},{"title":"Feed-Forward Networks","target":"Feed-Forward Networks","line":66},{"title":"Positional Encoding","target":"Positional Encoding","line":66}],"metadata":{"tags":["#extension"]},"task_lines":[],"tasks":{},"codeblock_ranges":[],"last_embed":{"hash":"hr6m8j","at":1770290019645}},"smart_blocks:Transformers/Multi-Head Attention.md#": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.05112434,0.00822925,0.03516324,-0.0358438,-0.09993005,0.01900995,0.06973511,0.00366685,0.02975842,0.00560613,-0.0065016,-0.03593617,0.02052293,0.06804997,0.10122269,0.02797442,-0.03334532,0.01561594,-0.03988483,-0.02887679,0.10627731,0.00734938,0.01709796,-0.00315192,0.02953994,0.01254918,0.00089969,-0.06611492,-0.0220597,-0.24415453,0.01219843,0.04837376,0.0620381,0.00960916,-0.0683038,-0.0117112,-0.0213252,-0.0011144,0.01257245,0.02303753,0.02733005,0.05966903,-0.02918153,-0.04069964,-0.10469382,-0.02458075,-0.08211644,-0.02321073,-0.04989431,-0.07372529,-0.01054717,-0.05401569,0.01818049,0.01172064,0.05432449,0.0380672,0.0002913,0.00917448,0.02771486,0.0175614,0.03564331,0.05265805,-0.12464556,0.0603427,0.07984475,0.01146017,-0.0669081,-0.02504937,-0.00941309,0.1020288,-0.03291985,-0.0427902,-0.0292597,-0.02668561,0.0223151,-0.02030427,-0.02314878,-0.00774882,0.03894981,-0.00716068,-0.0027057,-0.00294595,-0.05617959,-0.04249098,0.00287159,0.07231519,-0.0337071,-0.04498346,-0.02003209,-0.03617945,-0.02349457,-0.04529591,0.0172835,-0.02718975,0.02638627,0.0018133,0.04986694,-0.00026921,-0.05316725,0.11462218,-0.00016838,-0.06444556,0.04677274,-0.06118893,0.02880256,-0.01239011,0.04935061,-0.04540223,-0.03355799,0.06027112,0.03772742,-0.06719927,0.00716439,-0.05002943,0.03244217,0.04624588,0.02975968,0.02378298,0.0729444,-0.08833065,0.04185525,0.02086806,0.08354575,-0.05803712,0.01118234,-0.00982633,0.0710346,0.07003383,0.00996351,-0.01839825,0.07283014,-0.02849253,-0.03243608,-0.04659335,-0.0045389,-0.00847476,0.03096219,-0.00112499,0.0237497,0.02772688,0.01098031,-0.03485633,0.04359927,-0.09713795,0.00947659,0.14570664,0.00764786,-0.02159156,-0.05257002,-0.00052554,-0.06843052,0.0357006,0.01553243,-0.00387741,0.01739649,0.00347155,0.03838579,-0.00247861,-0.06742498,0.04550868,-0.03433613,0.01187952,-0.06232935,0.09311935,0.01568017,-0.05273012,0.01552225,-0.01975241,-0.03797691,-0.06112145,0.00868559,0.02168807,-0.0147734,0.04080767,0.04197165,0.0226157,-0.10138376,0.00134105,-0.02343413,-0.01234515,0.05193378,-0.0593948,-0.00771657,-0.00907171,-0.00408349,0.00433629,-0.00754706,0.00841852,0.00392543,0.0204354,-0.0890263,0.03794439,0.02435958,0.04140109,-0.07074388,0.01694312,-0.01708374,-0.05853379,0.02004013,-0.03450338,-0.02204246,-0.05377411,-0.04668989,-0.01696478,0.04672461,0.02303102,-0.00673361,-0.00708556,0.0810556,0.02764906,-0.08201588,-0.000685,0.03967474,-0.01669549,-0.04873207,-0.05088612,0.00785636,0.04788327,-0.02506802,0.00919845,0.02644763,-0.06347758,-0.07638903,-0.22652668,-0.04842366,-0.00922033,-0.02001478,0.05196494,-0.05847292,0.0569048,0.03157257,-0.00600203,0.08944343,0.10766827,-0.01348848,-0.09928352,-0.02555569,-0.02262808,0.04816764,-0.0073189,0.01566482,-0.05876654,-0.03125115,0.06489263,0.05498172,0.02269589,-0.09926526,0.01505374,-0.04066738,0.1619675,0.06233224,0.03609875,0.07387848,0.01798498,0.0269008,-0.01048439,0.00265835,0.0133743,0.00273347,0.01462224,-0.02725992,0.01558691,-0.00029573,-0.04023601,-0.03910478,-0.00687047,-0.02619525,-0.01255061,0.00961056,-0.0223833,-0.00367883,0.02153148,0.0152301,0.05931422,-0.11400215,-0.03000231,0.02893358,-0.01152546,-0.04340094,-0.08618795,-0.02717486,-0.08182945,0.02490505,-0.01117943,0.02434309,0.01271218,-0.04095247,0.04784917,0.06559107,-0.04466799,-0.00407626,-0.0162046,0.03131573,-0.03436519,0.0923655,0.0251649,0.02223536,-0.02685519,-0.0309635,0.08188218,-0.00595378,-0.03757339,0.04276448,-0.00137608,-0.02835297,0.00180481,0.02743225,0.02800109,-0.01708229,0.02227925,-0.06850442,0.04360493,-0.05999053,-0.02192365,-0.01236268,0.01933119,0.00839346,0.03168385,-0.03034049,-0.27939975,0.00547987,0.0617418,0.03849716,-0.06848808,0.07306001,0.022311,-0.04389288,-0.0025994,-0.00266832,-0.04320182,0.07488574,0.07121543,0.02302659,-0.02044468,0.03994473,0.03415685,0.00262596,0.0455606,0.01545631,-0.00400306,0.01316864,0.19368613,-0.00792854,0.04386871,-0.07847643,0.00806095,0.03406457,0.02767761,0.01407805,0.0138621,0.0493741,0.04200483,-0.0994749,0.03301422,0.04554703,-0.01073432,0.03290197,0.06075289,0.03799234,-0.00106493,0.04680072,-0.00229191,-0.03688498,0.13144514,-0.02366932,-0.00921093,0.00076318,-0.09001665,0.01166002,-0.00661879,0.03784307,0.04475192,0.06058528,0.08059844,0.03342948,0.03184263,0.02832985,-0.02521154,-0.01347299,0.03185067,0.01277326,-0.00170911,0.03283686,0.03332765],"last_embed":{"hash":"7uwz5u","tokens":140}}},"text":null,"length":0,"last_read":{"hash":"7uwz5u","at":1770290019869},"key":"Transformers/Multi-Head Attention.md#","lines":[6,17],"size":523,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"7uwz5u","at":1770290019869}},
"smart_blocks:Transformers/Multi-Head Attention.md##1. Why Multiple Heads?": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.04475402,-0.0211224,0.04753753,0.00585878,-0.11674345,0.00636564,0.04490747,-0.02832018,0.06785224,0.00458113,-0.0196038,-0.0593743,0.03667058,0.06120116,0.07563618,0.03820902,-0.03874064,-0.01094236,-0.07540742,-0.01480983,0.07371533,0.0086592,0.01493401,-0.00009516,0.02361317,0.03521879,-0.01811376,-0.08801932,-0.02020652,-0.20601495,0.01271932,0.06573745,0.01183888,0.03562834,-0.05954128,-0.01208333,-0.00068843,0.00778271,0.00828691,0.05810374,0.01256987,0.01353539,0.0043678,-0.04540521,-0.0716933,-0.0258995,-0.09598094,-0.01313243,-0.06460962,-0.06284473,-0.00375856,-0.0573798,0.01309556,-0.00954617,0.04482766,0.06574355,0.02231364,0.02911008,0.0253984,0.02576555,0.03869907,0.08125224,-0.15467903,0.08834449,0.04406191,-0.01254765,-0.0754052,-0.00219904,-0.0416688,0.13129996,-0.01350723,-0.06302304,-0.05829856,-0.00054313,0.02841988,-0.00589429,-0.01306895,0.01728683,0.04078705,-0.01641047,-0.01456355,-0.00507199,-0.04427607,-0.04426083,-0.0151876,0.0487489,-0.04071677,-0.0741742,-0.0316563,-0.02636354,-0.02737158,-0.0400112,0.04415764,-0.01532666,0.00607016,-0.016839,0.04099013,0.00381854,-0.03303693,0.11075781,-0.00202408,-0.06972027,0.04559036,-0.05129172,0.02079814,0.00669769,0.01269735,-0.0380258,-0.01917048,0.03544748,0.0237318,-0.03177665,0.02036093,-0.07592082,0.05097224,0.02097129,0.01378589,0.02069112,0.05816925,-0.06727191,0.02332456,-0.03164299,0.05359538,-0.01452412,-0.02350975,-0.0378729,0.06070261,0.04940199,0.03981955,-0.03411786,0.07440804,0.00067755,-0.03879245,-0.03142662,-0.00029619,-0.01869493,0.00725213,-0.0068861,0.03320177,0.02195812,0.01914064,-0.05986813,0.00026803,-0.08396138,-0.02695916,0.15199566,-0.03304362,-0.02471192,-0.06824306,0.05646358,-0.06912664,0.03753264,-0.00497635,-0.02665425,0.00501894,0.00828244,0.05681075,-0.05187024,-0.06111202,0.01633475,-0.01501551,-0.02192175,-0.08097871,0.07685662,0.03161011,-0.08077111,-0.0015293,-0.00109613,-0.02801894,-0.04286904,0.05325564,0.03473665,-0.03854944,0.03300083,0.03500677,0.01333252,-0.10581706,0.00453115,-0.01980891,-0.01223883,0.10809118,-0.03161412,-0.04309017,0.0095819,0.00424657,-0.02474982,-0.04206892,-0.01664441,0.00499055,0.04090966,-0.06115744,0.00051045,0.06438548,0.01477431,-0.04766709,0.02753154,0.01068586,-0.03730953,0.0535864,0.00569813,-0.04843633,-0.03903243,-0.01785087,-0.01846031,-0.0157154,0.01442744,0.00132562,-0.0076873,0.07991085,0.02612902,-0.08161098,0.03946782,0.01487769,-0.0166098,-0.01583912,-0.02169992,-0.00963337,0.06279728,0.03141877,0.03292835,0.01768029,-0.0566945,-0.00916018,-0.21867077,-0.04402261,0.01523731,-0.04617293,0.05559397,-0.02134739,0.03386421,0.06086785,-0.05451064,0.10057625,0.09608427,-0.03190129,-0.08203981,-0.0396561,-0.04425106,0.07893514,0.03085041,0.01243393,-0.04352101,-0.00133432,0.04650958,0.04174271,0.02164902,-0.09508173,0.02584941,-0.03202851,0.1576952,0.04846057,0.04479791,0.07718985,0.04633213,0.05347194,-0.02649745,-0.01842407,0.03470694,-0.00606229,0.00001188,-0.05899047,0.01710921,-0.02170334,-0.04517707,-0.0123388,-0.01742885,-0.02938781,0.0095792,0.01020811,-0.01584205,-0.04219824,0.02797367,0.01252233,0.02078167,-0.04995778,-0.0017215,0.06168175,-0.02168737,0.02330045,-0.11185908,-0.02542832,-0.03966403,-0.01156808,0.03799049,0.04003417,0.05432415,-0.04342146,0.04256107,0.06046554,-0.0275725,-0.00461665,-0.0458822,0.03768323,-0.03320761,0.1329383,0.01494604,0.01415471,-0.02845882,-0.00565886,0.01094948,0.00526006,-0.05207587,0.03767464,0.02821234,-0.12063953,0.04268859,0.05023815,0.03159975,-0.00552756,0.02138875,-0.04531951,0.10250796,-0.04087421,-0.02055837,-0.01115507,-0.00251571,0.01401624,0.03942617,-0.02843042,-0.27811608,0.01051583,0.06380948,0.03955496,-0.04387699,0.10157257,-0.01394385,-0.04269649,0.00021766,0.01430126,0.01132996,0.03460801,0.06251968,0.00912109,-0.00349306,0.04850349,0.01329571,0.00441541,0.03696602,0.02516709,0.01065787,-0.00381712,0.18369396,-0.00917653,0.05083486,-0.03693227,-0.01695003,0.01423819,0.05034519,0.04120557,0.00937386,0.02681387,0.09503061,-0.08309906,0.01893453,0.0256217,0.00329077,-0.04696083,0.05168425,0.01813845,-0.0323107,0.02000738,-0.01899273,-0.08803841,0.12770359,-0.00431269,0.01732126,-0.01385427,-0.05653492,0.02923472,-0.02204997,-0.00946202,-0.03044336,0.05413221,0.07227591,0.02823294,0.05703736,0.02890556,-0.03960463,0.00816991,0.02043129,-0.04097043,-0.01795715,0.03213023,0.03701643],"last_embed":{"hash":"16u03pa","tokens":176}}},"text":null,"length":0,"last_read":{"hash":"16u03pa","at":1770290019925},"key":"Transformers/Multi-Head Attention.md##1. Why Multiple Heads?","lines":[18,30],"size":607,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"16u03pa","at":1770290019925}},
"smart_blocks:Transformers/Multi-Head Attention.md##2. The Math of Multi-Head Attention": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.08301431,-0.01688757,0.00544672,-0.0636811,-0.09486671,0.01851478,-0.00698581,0.04867351,0.05177903,0.03121665,0.00988522,-0.05962912,0.02773155,0.05183387,0.05250462,0.03813677,-0.03173239,-0.00322034,-0.06404373,-0.02506059,0.08870512,0.01828675,0.01379289,0.00485552,0.05761411,0.03821205,-0.02682182,-0.06814537,-0.03079652,-0.24836564,0.04298846,0.01037341,0.06272878,0.00308734,-0.04493079,-0.04277924,-0.03240343,0.03956582,0.00447172,0.01685107,0.0210082,0.04353723,-0.00909879,-0.05192177,-0.0642781,-0.06773153,-0.11338164,-0.00700407,-0.01571901,-0.02444439,0.01025698,-0.04460108,0.03496007,0.03927984,0.05621842,0.03471132,0.01085116,0.03648078,0.06701565,0.01745328,0.0387876,0.02998286,-0.16206653,0.11025476,0.05751247,-0.02368435,-0.07697074,-0.0433622,0.0094801,0.08971272,-0.0246996,-0.02777708,0.04238411,-0.02523609,0.02987553,-0.02023433,-0.02942635,0.01464134,0.02006696,-0.01766509,0.02169046,0.03320285,-0.03582423,-0.01155217,0.00312573,0.0550667,-0.0346378,-0.0094849,0.01858696,-0.01791066,-0.01837903,-0.04996729,-0.02109528,-0.01841744,0.02591897,0.0115923,0.03392951,0.00286172,-0.05016229,0.10544709,0.00156924,-0.0536427,0.02597829,-0.04632833,0.00841845,-0.00932595,-0.00767256,-0.03457199,-0.06166658,0.02399784,0.03636216,-0.04853168,0.01743254,-0.050027,0.01582972,0.01207788,0.00361347,0.06604873,0.01277818,-0.067191,0.02943175,-0.00422446,0.07791036,-0.01262894,0.03543777,0.02392798,0.05328462,0.06969428,0.00991972,0.04452583,0.06819797,0.04232245,-0.06459056,-0.02015367,0.00208887,-0.00135664,0.04280053,0.00155072,-0.00142255,0.00445299,0.00434839,-0.0235995,-0.00348394,-0.0832888,0.00439934,0.14447509,-0.04687565,-0.0167879,0.00351723,-0.03665386,-0.05188664,0.05165059,-0.01320024,-0.02823004,0.03864744,-0.02179919,0.014287,0.0126173,-0.07580008,0.03694486,-0.04448232,0.02851751,-0.03337584,0.08500685,0.00307192,-0.05777871,0.00601513,0.01350496,0.01969296,-0.05527657,0.02749218,0.01067077,-0.00783209,0.01029337,0.06888966,0.01391368,-0.13492581,0.01678484,0.0160904,-0.0003523,0.03783182,-0.04225589,-0.00280267,-0.02456808,-0.01955009,-0.03825401,0.01646834,-0.02925332,-0.04597748,0.08309095,-0.10891372,0.02031337,-0.0319575,0.04176522,-0.04058753,0.0047212,-0.03913085,0.00958366,0.04944273,-0.02372219,-0.00132993,-0.05042015,-0.01921693,0.00866491,0.016172,0.04547232,-0.00478772,-0.00812696,0.0564438,0.03526074,-0.06382883,-0.00991343,0.07488244,-0.05650837,-0.07894909,-0.01920858,0.01940053,0.06951068,-0.03957207,0.0512633,0.02037252,-0.09648574,-0.08986995,-0.2090904,-0.07683031,0.0492433,-0.01141281,0.05010021,-0.06540211,0.05002486,0.01125129,0.00283309,0.06789131,0.11016133,0.04336109,-0.10708626,-0.04636098,-0.04649387,0.01677961,-0.00253964,0.06384029,-0.0067747,-0.01890354,0.06718882,0.03632037,0.03120267,-0.06961242,0.03905457,-0.06065221,0.16355632,0.00267713,0.03046719,0.0749681,0.03222289,0.05238532,0.00569851,0.00693454,0.02284827,-0.03527759,-0.00512758,0.00815748,0.0133102,-0.01224363,-0.04515949,-0.01546677,-0.02192475,-0.05560207,0.04305414,0.01318586,-0.04514446,0.00445625,-0.01285437,0.01747534,0.0942574,-0.09272552,-0.01824005,0.01805076,0.01491007,-0.0547246,-0.09243751,-0.02268795,-0.07250718,0.01486235,-0.02777893,-0.01028733,0.020257,-0.03839672,0.00423658,0.07022876,-0.01385625,0.02568428,-0.02349067,-0.02388733,-0.03136778,0.0767518,0.05670869,0.02714589,0.01132934,-0.03449675,0.08430902,0.00060831,-0.03109438,0.02777267,0.01144985,-0.02768998,0.01449646,0.03855693,0.04780218,-0.01457911,0.01276305,-0.04359376,0.00837696,-0.03309552,-0.01696082,-0.01765791,0.04814668,0.05229019,-0.00236815,-0.01643761,-0.27517021,0.02933252,0.05165009,0.01765197,-0.05054174,0.03951769,0.03587422,-0.02620972,0.01952533,0.00533815,-0.08659928,0.06873067,0.02473193,0.0025625,-0.00504769,0.02097125,0.01178618,-0.01664704,0.01851316,-0.00789137,-0.05767524,0.00980788,0.21134506,-0.0239455,0.03601847,-0.0750635,-0.04008426,0.0191905,0.05460522,0.035322,-0.02412602,-0.00576277,0.08277521,-0.09037317,0.03930688,0.05517757,-0.04379274,-0.00371904,0.04499294,0.04638593,0.05308449,0.03072281,-0.01587916,-0.03866712,0.11797156,0.01632897,-0.02721136,-0.06305553,-0.05285516,0.00997316,0.00741147,0.03877215,0.05905431,0.0342903,0.052824,0.06134114,-0.01959722,0.00450256,-0.03224897,0.00369436,0.03316643,-0.0409479,0.00322518,0.00534568,-0.00332933],"last_embed":{"hash":"10k4h6p","tokens":391}}},"text":null,"length":0,"last_read":{"hash":"10k4h6p","at":1770290019997},"key":"Transformers/Multi-Head Attention.md##2. The Math of Multi-Head Attention","lines":[31,57],"size":1166,"outlinks":[{"title":"Scaled Dot-Product Attention","target":"Attention","line":13}],"class_name":"SmartBlock","last_embed":{"hash":"10k4h6p","at":1770290019997}},
"smart_blocks:Transformers/Multi-Head Attention.md##2. The Math of Multi-Head Attention#Step A: Split and Project": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.07658367,-0.01257897,0.0314824,-0.07592739,-0.11187685,0.01497964,-0.02483607,0.03532632,0.03725153,0.04819776,0.00527225,-0.06214923,0.02391868,0.04257797,0.06111158,0.04505695,-0.04363016,-0.00050099,-0.07406714,-0.00780089,0.11943067,0.03141085,0.00320623,0.021162,0.02709001,0.01837794,-0.02049158,-0.06538539,-0.02053056,-0.23548034,0.03033936,0.02209692,0.08543467,-0.01265509,-0.04803121,-0.056512,-0.0303849,0.0253679,-0.00760418,0.02159709,0.02567553,0.04793248,0.01274339,-0.05143839,-0.0543377,-0.05678865,-0.10618963,0.01206302,-0.01994678,-0.04132137,0.01920364,-0.03163736,0.02087747,0.03732194,0.04392241,0.00661646,0.02568894,0.0322447,0.06786972,0.032881,0.02935044,0.03821171,-0.15200301,0.09240779,0.04754924,-0.00188377,-0.09765272,-0.0523428,-0.00151108,0.08611313,-0.0239385,-0.02792105,0.05025234,-0.02595106,0.03854356,-0.00708221,-0.02606102,-0.00627132,0.0297555,-0.01426456,0.00198024,0.01146951,-0.02880502,-0.01568056,-0.01399631,0.05169594,-0.02425897,-0.01028985,-0.0230499,-0.01608008,-0.03063929,-0.03978778,-0.02731771,-0.02329586,0.02793326,-0.00672535,0.01979867,0.00278744,-0.05344737,0.12207641,-0.00242136,-0.05749962,0.02783428,-0.07483565,-0.01325339,-0.02408473,0.00729027,-0.02548924,-0.06380576,-0.00619023,0.02492252,-0.03001293,0.02412702,-0.05733547,0.0095073,0.00319247,-0.01302001,0.06940693,0.0065178,-0.06754915,0.03840635,0.00128218,0.06832714,-0.00911347,0.02773303,0.02803952,0.03795406,0.05362682,0.0067505,0.05990152,0.04470231,0.03220234,-0.04146522,0.0022012,0.00061333,-0.00859329,0.04320076,-0.00617996,0.00146757,0.0340175,0.00957272,-0.02182715,-0.0098245,-0.08037966,-0.01386085,0.13884331,-0.04752384,-0.0278438,0.01590677,-0.01860532,-0.05730562,0.06456163,-0.00422879,-0.01613419,0.04842425,-0.0002323,0.01686084,-0.01497613,-0.08278231,0.0407346,-0.03813052,-0.00353247,-0.02555338,0.09511411,-0.00039317,-0.05112895,0.01996423,-0.01157499,0.01404885,-0.0611468,0.01888984,0.05201631,-0.01132347,0.02045983,0.07916906,0.01717844,-0.09066127,0.00325219,0.00558572,-0.02798027,0.03620232,-0.02874192,0.00155579,-0.00372484,-0.02568426,0.0008339,0.02281863,-0.02599757,-0.04394562,0.06571975,-0.08460859,0.02211151,-0.04487651,0.04727466,-0.01920609,0.00978123,-0.04710947,-0.00946529,0.03183017,-0.00337364,0.00199961,-0.03812754,-0.01332103,0.02405627,0.01190875,0.05592523,0.00953037,-0.01269454,0.05632487,0.06500078,-0.06759908,-0.01210817,0.0913654,-0.06006765,-0.05654565,-0.01121764,0.04184585,0.0470746,-0.0529711,0.02209743,0.02640118,-0.09804341,-0.09649321,-0.20977314,-0.07015492,0.05292045,-0.00984356,0.08952715,-0.05712173,0.06568929,-0.01316309,-0.02057503,0.07778887,0.11316929,0.01977944,-0.09935535,-0.03664813,-0.05778743,0.0296095,-0.00196904,0.00866631,-0.04404468,-0.01141724,0.05462456,0.02280314,0.04628835,-0.08185261,0.01918811,-0.04125862,0.15958719,0.00711672,0.05554745,0.07504993,0.05792517,0.04504594,-0.00824411,0.01717555,0.03384006,-0.04326686,-0.01233631,0.00414035,0.03033256,-0.01315959,-0.0351852,-0.03446132,-0.01211684,-0.04840419,0.06046369,-0.00621173,-0.03779458,-0.00087035,-0.00390238,0.02582754,0.07420127,-0.0947559,-0.01938985,0.02305665,0.0073915,-0.04889032,-0.09215634,-0.0269089,-0.10200732,0.01014709,-0.01857801,-0.02944669,0.01191042,-0.05166407,-0.00042445,0.0556766,-0.03537567,0.01441203,-0.02775444,-0.0358283,-0.0198003,0.05177887,0.0644431,0.02916453,0.00788063,-0.0180162,0.06045282,0.02835462,-0.03238352,0.03010199,0.01838697,-0.04870027,-0.01829573,0.03901982,0.03711909,0.0029951,-0.01252497,-0.04266986,0.04085628,-0.04713799,-0.00275449,-0.00335922,0.03413249,0.07572059,0.0116392,-0.03022165,-0.28122145,0.04410281,0.05697871,0.03397561,-0.05674409,0.06024003,0.03201748,-0.01976046,0.03061012,-0.00621878,-0.04821733,0.07086914,0.02304855,0.02622876,-0.00436027,0.02955182,0.00583775,-0.01257574,0.03200831,-0.00921944,-0.04026816,0.02796559,0.20575361,-0.00893335,0.03709433,-0.08229387,-0.03791857,0.04561813,0.03874035,0.0344491,-0.01079373,-0.01287239,0.08741663,-0.09964711,0.06789945,0.06506779,-0.02877909,-0.01795896,0.0272864,0.06249643,0.03263458,0.00010998,-0.03065009,-0.04455571,0.10900036,0.00349994,-0.03248936,-0.06257971,-0.0409817,0.00169697,0.03336146,0.04625454,0.04159966,0.02185147,0.07203078,0.0766812,0.0129094,0.00295538,-0.04438385,-0.02480739,0.0207716,-0.03966524,0.00648838,-0.00951084,0.02232905],"last_embed":{"hash":"wt6kin","tokens":112}}},"text":null,"length":0,"last_read":{"hash":"wt6kin","at":1770290020187},"key":"Transformers/Multi-Head Attention.md##2. The Math of Multi-Head Attention#Step A: Split and Project","lines":[34,41],"size":263,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"wt6kin","at":1770290020187}},
"smart_blocks:Transformers/Multi-Head Attention.md##2. The Math of Multi-Head Attention#Step B: Parallel Attention": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.07770514,-0.00095148,0.03819828,-0.05908847,-0.08179615,0.01327743,0.03350607,0.03520282,0.05935825,0.02445297,-0.00619398,-0.05136609,0.01383057,0.04165431,0.04975537,0.02432429,-0.01504388,-0.00560457,-0.06017585,-0.06009318,0.0979092,0.00850938,-0.00102704,-0.00871702,0.06162154,0.02942473,-0.01901626,-0.05725895,-0.01031188,-0.22629528,0.07130095,0.02884606,0.05910311,0.00511888,-0.04316042,-0.0528234,-0.03413851,0.04729933,0.00142357,0.02375017,0.01656281,0.04404692,-0.04826963,-0.06955113,-0.06925977,-0.05500227,-0.11617681,-0.01301333,-0.01663633,-0.04486886,-0.00341328,-0.04604931,0.05995617,0.00641416,0.03140062,0.021255,0.00252698,0.02785973,0.05648127,0.01601499,0.02787723,0.03373039,-0.14009395,0.08658255,0.04465453,-0.0221677,-0.06624326,-0.03484953,-0.00224971,0.08496103,-0.04233418,-0.0351903,0.0184343,-0.01692877,0.01268209,-0.03381646,-0.04735407,-0.00179444,0.00326393,-0.02111377,0.01687787,-0.00087361,-0.04432803,0.00482475,0.02072665,0.06058011,-0.02738948,-0.01478792,0.03665762,-0.0594004,-0.02187835,-0.04116167,0.00063611,-0.03451427,0.0412353,0.01500631,0.01385289,0.00606632,-0.007103,0.11459259,-0.00371914,-0.05495841,0.02892292,-0.04774086,0.02890624,-0.02228315,0.02202636,-0.03752138,-0.08925922,0.04858661,0.04233648,-0.05856916,0.01458421,-0.03761704,0.04726181,0.00502249,0.01495904,0.03454731,0.0550229,-0.07311483,0.0553121,0.01253419,0.08172632,-0.03754186,0.03108937,0.00883794,0.06471943,0.06130762,0.01721603,0.00049155,0.07934415,0.02405625,-0.06363305,-0.00971345,0.00143357,-0.00838603,0.01232872,-0.02243958,0.00688489,0.01802706,0.01680364,0.0030343,0.01931779,-0.08849948,0.00735579,0.17278028,-0.02096028,-0.02417344,0.00671381,-0.04286455,-0.05882894,0.04289589,-0.00707581,-0.01831706,0.00438883,-0.00959324,0.01040199,0.01772454,-0.0447419,0.02969452,-0.05867454,0.04749955,-0.02035941,0.10321961,-0.0141641,-0.05590309,-0.00727063,0.02682227,-0.00963944,-0.04683836,0.02512952,0.00121987,-0.01369885,0.03612679,0.06719676,0.00627889,-0.12056015,-0.00196628,0.00002978,-0.02180278,0.05473363,-0.06124955,0.01368797,-0.02795953,-0.0291236,-0.025155,0.01373737,0.00223219,-0.01703193,0.08409329,-0.08367013,0.00512961,-0.03096534,0.04159453,-0.0513999,-0.00346625,-0.00595646,-0.02519589,0.03929086,-0.02566908,-0.00627307,-0.04576397,-0.01947286,0.02895616,0.05140071,0.03347618,-0.02243945,-0.00241342,0.08124994,0.01533747,-0.07171768,-0.01103233,0.05243312,-0.05397749,-0.09313715,-0.03571729,-0.00185458,0.05978709,-0.02440603,0.03421843,0.02732327,-0.08845983,-0.09361803,-0.19214056,-0.08944974,0.04738849,-0.01148354,0.04331272,-0.04634022,0.03560543,0.04958772,0.00337048,0.07762716,0.12639098,0.01492392,-0.10439491,-0.05828344,-0.03823729,0.02739909,-0.00499877,0.04844686,0.0006278,-0.01532788,0.07993504,0.03392169,0.04240169,-0.0773203,0.01076815,-0.06712352,0.16099776,0.02789514,0.0544832,0.05699795,0.01050803,0.04983437,-0.02007532,0.01206528,0.0040957,0.00540359,-0.00963074,0.00133696,0.02473347,-0.02003615,-0.04142299,-0.00702965,-0.01762443,-0.05213242,0.01325121,0.01139562,-0.04460659,-0.02058487,-0.01151087,0.01857529,0.08531856,-0.10835813,-0.0260033,0.04146874,-0.00049486,-0.08005899,-0.06333358,-0.01938892,-0.09065846,0.02447543,-0.01868745,0.00014116,0.01598876,-0.00609401,0.02251464,0.08973284,-0.02881143,-0.00610705,-0.01191922,0.01496734,-0.03164448,0.0707693,0.04143268,0.04480039,-0.01195134,-0.04052525,0.11171272,0.01860895,-0.04378942,0.02529505,0.01109319,0.00669744,0.00232359,0.03114887,0.02089569,-0.01833061,0.00041945,-0.04227616,0.015518,-0.0434608,-0.00399266,0.01143417,0.02585694,0.03997111,-0.00102512,-0.00390431,-0.27567995,0.01734731,0.03427649,0.03170907,-0.02357724,0.05635963,0.02942601,-0.04960448,0.01432462,0.03921315,-0.08419197,0.06580991,0.03437823,0.01211555,-0.01197236,0.03350519,0.01660672,-0.01873089,0.04682185,-0.00256972,-0.02956216,0.02147367,0.20251355,-0.01442645,0.03359203,-0.08403174,-0.03561273,0.01386484,0.07708555,0.04270459,-0.01976534,-0.00572562,0.10127169,-0.08454438,0.03122426,0.06440403,-0.03594162,-0.01373799,0.03853205,0.03554183,0.04319511,0.01607934,-0.03320513,-0.04722848,0.10853051,0.01751977,-0.02861517,-0.07415314,-0.06092413,0.040094,-0.01462696,0.02890947,0.03400362,0.03141552,0.06020605,0.06935166,0.00053182,0.00275936,-0.03192136,-0.01211733,0.03820644,-0.06539872,0.00571818,0.04219373,-0.00228922],"last_embed":{"hash":"kblx6w","tokens":104}}},"text":null,"length":0,"last_read":{"hash":"kblx6w","at":1770290020231},"key":"Transformers/Multi-Head Attention.md##2. The Math of Multi-Head Attention#Step B: Parallel Attention","lines":[42,46],"size":268,"outlinks":[{"title":"Scaled Dot-Product Attention","target":"Attention","line":2}],"class_name":"SmartBlock","last_embed":{"hash":"kblx6w","at":1770290020231}},
"smart_blocks:Transformers/Multi-Head Attention.md##2. The Math of Multi-Head Attention#Step C: Concatenate": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.10118794,-0.02956306,0.03469242,-0.05971232,-0.0863283,0.0198085,-0.01156468,0.063182,0.03063865,0.01434642,0.01820276,-0.07066672,0.00922103,0.04574033,0.07084186,0.03169744,-0.04882317,0.00785857,-0.03683757,-0.01678337,0.09408038,0.02093779,-0.00726736,-0.00871819,0.03123451,0.01155112,-0.03142715,-0.08448626,-0.02189004,-0.25505382,0.01835542,0.01337114,0.03894448,-0.00105651,-0.05268608,-0.03701531,-0.02496027,0.0191337,0.0217598,0.04994443,0.02679496,0.01907868,-0.05221311,-0.06287213,-0.05872839,-0.07781781,-0.09005029,-0.01453496,-0.01378195,-0.05563174,0.00903266,-0.04993885,0.02347803,0.03165758,0.05281755,0.03478037,0.01512985,-0.00160368,0.06654872,0.03165377,0.00858105,0.05437306,-0.15011416,0.10518844,0.03276806,-0.0248199,-0.07354244,-0.02214564,0.00594447,0.08118508,-0.03007863,-0.02996548,0.0083421,-0.01775344,0.02244898,-0.03099003,-0.03379618,0.0093653,0.04779676,0.01406429,-0.00279836,0.02575187,-0.02693325,-0.01793631,0.01429083,0.03751034,-0.02009798,-0.01151142,0.00467095,-0.03318501,-0.00186761,-0.02249475,-0.02678687,-0.02185648,0.0223834,0.02139965,0.03943894,0.00584907,-0.02403896,0.10515995,0.0182316,-0.05087933,0.00827735,-0.07247573,0.03239233,0.00298271,-0.01457144,-0.0324697,-0.05344964,0.01934414,-0.01291909,-0.05201909,0.04254327,-0.03204536,0.04231917,0.00670466,-0.00490878,0.03496627,0.04003314,-0.09386714,0.0568522,-0.01232783,0.07042626,-0.04956901,0.02735596,0.02679896,0.06018882,0.06354596,-0.00003836,0.04839758,0.09413604,0.0433096,-0.06223598,-0.01801303,-0.01162435,0.00075349,0.02339676,0.0163456,-0.04070795,0.00525571,-0.00376113,-0.02425631,-0.01467512,-0.0893491,0.00385451,0.12905599,-0.04144988,-0.03270584,-0.0216876,-0.02230972,-0.04963464,0.04266689,0.01125,-0.01724303,0.03578395,-0.0134588,0.01326726,0.01401189,-0.07791115,0.03273626,-0.03472308,0.01486173,-0.04328081,0.13890572,-0.02102895,-0.07291455,0.02795375,-0.0092447,0.02951361,-0.04747343,0.00938276,0.01550109,0.01341994,0.04535006,0.09530591,0.01716184,-0.13468944,0.00880751,0.00901005,-0.00406066,0.05048817,-0.04564079,-0.01306147,-0.0251029,-0.04335336,-0.01436115,0.0126268,0.01348746,-0.01645572,0.05408905,-0.09674447,0.01538802,-0.01103545,0.02941773,-0.03340992,-0.00237719,-0.02584871,-0.00745104,0.07628299,-0.02720264,-0.00336017,-0.04070775,-0.05205597,-0.00280855,0.02839676,0.0462327,0.01374778,-0.0056556,0.0677601,0.02439249,-0.08138422,-0.01400796,0.07914674,-0.06062974,-0.0590517,-0.00191065,0.01422208,0.05542938,-0.02912326,0.03330385,0.02539621,-0.0786536,-0.07950269,-0.21632412,-0.05466378,0.02958205,-0.02502044,0.04285717,-0.06412511,0.02786614,0.03992266,0.00356811,0.03681692,0.09513915,0.01665236,-0.09759923,-0.03159034,-0.05191316,0.0060937,0.01620347,0.03120496,-0.00687352,-0.01394478,0.05510827,0.03299209,0.00525981,-0.09337677,0.03727454,-0.04395646,0.17927556,0.02993966,0.0235828,0.05796767,0.01011023,0.04226983,-0.01329629,0.0111839,0.02962069,-0.02604915,-0.0158133,0.01105325,0.02263948,-0.00581417,-0.05022165,-0.00721626,-0.00134925,-0.04995728,0.04954425,-0.00046807,-0.04135023,-0.00127461,-0.01366211,0.02519385,0.05492646,-0.0946012,-0.00385256,0.03014233,0.00151832,-0.03454612,-0.06365077,-0.03219211,-0.07288981,0.01470516,-0.0051316,0.03274804,-0.01402895,-0.04594377,0.01677777,0.09247325,-0.023247,-0.00216681,-0.0047937,-0.04351506,-0.01677996,0.06255579,0.06787719,0.02445372,0.000089,-0.0277462,0.0971748,0.03236948,-0.01386099,0.02782504,-0.01345402,-0.01545972,0.02922408,0.01678461,0.02315492,0.01285196,0.00635963,-0.0390992,0.03217522,-0.07387485,-0.0433947,-0.02622108,0.04429627,0.01843116,0.00475635,-0.0443124,-0.28672484,0.02464034,0.05552961,0.02901231,-0.04888983,0.07827377,0.03651841,-0.02074441,0.00680784,0.01859703,-0.08116975,0.07330097,0.04318782,0.00665892,0.01159105,0.01872942,0.01235568,-0.03215141,0.04194895,0.00788457,-0.05644033,0.02337394,0.21275198,-0.00825815,0.02821885,-0.05305532,-0.04318741,0.03203653,0.05823074,0.05026724,-0.02245591,0.02246251,0.08492474,-0.09293773,0.03785274,0.06218243,-0.04740681,0.00073927,0.04383432,0.04182027,0.03992258,0.02933254,-0.00718045,-0.03204675,0.08919475,0.01810154,-0.02630016,-0.03016003,-0.04638625,-0.002749,0.00131081,0.052804,0.01821608,0.04866879,0.07266326,0.10168552,-0.00535103,0.00346145,-0.02047024,0.00654479,0.04547881,-0.0351822,0.01997199,0.03416838,-0.00542988],"last_embed":{"hash":"geetqe","tokens":118}}},"text":null,"length":0,"last_read":{"hash":"geetqe","at":1770290020272},"key":"Transformers/Multi-Head Attention.md##2. The Math of Multi-Head Attention#Step C: Concatenate","lines":[47,51],"size":271,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"geetqe","at":1770290020272}},
"smart_blocks:Transformers/Multi-Head Attention.md##2. The Math of Multi-Head Attention#Step D: Final Linear Projection": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.06601994,-0.02160035,0.02595706,-0.06232153,-0.08562226,0.01477533,0.00521501,0.05270349,0.05111709,0.03773678,0.05940036,-0.06321519,0.01300019,0.04729655,0.05680048,0.05048457,-0.03231426,0.04270551,-0.05351802,0.00320711,0.09873155,0.02887918,-0.00462,-0.01559135,0.07580826,0.04830818,-0.02210074,-0.10049841,-0.02093814,-0.24555592,0.0090529,0.02381442,0.05460358,-0.01874569,-0.0217777,-0.07505,-0.01559519,0.03599624,-0.02076148,0.03571326,0.02875435,0.01702943,-0.03209114,-0.07071032,-0.04249667,-0.08931332,-0.09403235,0.0098569,-0.02686543,-0.0289199,-0.00036865,-0.0454811,0.0450472,0.013425,0.05934598,0.04295393,0.00667821,0.00727673,0.06004742,0.04034587,0.05429841,0.03546,-0.16162869,0.09558428,0.06167242,-0.02692676,-0.07597054,-0.0509926,0.0060984,0.08973563,-0.01216785,-0.05220258,0.06346451,-0.01964352,0.02563899,-0.01963439,-0.01242212,0.01613461,0.04786812,-0.00142684,0.01916509,0.04193307,-0.03165832,0.00108188,0.03218964,0.04467689,-0.024518,-0.01163168,0.03564782,-0.01839256,-0.03478907,-0.04622689,-0.03337836,-0.00788548,0.01205739,0.00966039,0.0356134,0.00266737,-0.01324025,0.11198524,0.00341445,-0.05308349,0.04572394,-0.05216465,-0.01156823,0.00238387,-0.01908407,-0.02467611,-0.04366094,0.00440161,0.012967,-0.05759722,0.02741471,-0.02805718,0.01585456,0.01385303,0.03461072,0.06018838,0.01464538,-0.05184301,0.05586886,-0.01116108,0.02961377,-0.00799235,0.02242891,0.00334406,0.04352415,0.08759537,-0.00779977,0.05308728,0.0579693,0.05575244,-0.05451367,-0.01122141,-0.00856395,0.00846222,0.03001618,0.00429262,0.00449324,0.01010644,0.01472715,-0.02959841,-0.00466944,-0.08158587,-0.01791283,0.14787808,-0.02545124,-0.02275729,0.0218948,-0.02428664,-0.02736861,0.00185174,0.00242897,-0.01122045,0.00681075,-0.01179166,-0.00010322,0.03268394,-0.09603895,0.05601424,-0.05370836,0.0226818,-0.02147699,0.12538546,-0.01678802,-0.06721686,0.03710729,-0.01111903,0.0180883,-0.05171129,0.00604361,0.01488975,-0.0090222,-0.01480431,0.05442679,0.00805014,-0.11424176,0.02196286,0.03852046,-0.02093507,0.0349915,-0.04417911,-0.01914256,-0.00907365,-0.02319301,-0.03047701,0.02773342,-0.00985865,-0.03588963,0.04621428,-0.10582262,-0.00254536,-0.01817627,0.0217396,-0.03885363,-0.02514942,-0.02310507,-0.00419914,0.0656196,-0.00558569,-0.00938913,-0.0354065,-0.04650762,0.01254867,0.07166364,0.02932521,0.03075468,-0.03976706,0.05078186,0.05201193,-0.07535683,-0.00728471,0.06702467,-0.03538241,-0.09219872,-0.00752916,-0.01885192,0.05018844,-0.05060134,0.0285292,0.0253178,-0.08865789,-0.08942798,-0.22266367,-0.08256613,0.04265622,-0.03896451,0.04991186,-0.0778798,0.02561732,0.01790387,-0.02289651,0.05931887,0.10049883,0.04038128,-0.11443489,-0.03871371,-0.05019953,0.00287815,0.02588329,0.01042586,-0.02017501,-0.02213274,0.03563584,0.03892152,0.02133978,-0.07065133,0.01832673,-0.05419781,0.15976691,0.01805401,0.01837893,0.08604245,0.03511143,0.05770263,-0.03502832,0.02708388,0.00751187,-0.00297459,0.01240655,-0.0173738,0.0646767,-0.027367,-0.03287519,-0.00051358,-0.00964144,-0.05814708,0.0513939,-0.01322645,-0.06323348,-0.01530681,0.01007059,0.02179164,0.08930808,-0.08842446,-0.00927729,-0.00289437,0.01071507,-0.02419071,-0.05192532,-0.02329428,-0.07076385,0.02198548,-0.02015101,-0.00030223,0.01131455,-0.01249065,-0.00210009,0.07925134,-0.01566157,-0.0114581,-0.01914419,-0.028732,-0.01614075,0.05737313,0.02860739,0.02434516,0.03460953,-0.01857624,0.08277028,0.01027063,-0.03233809,0.0215708,0.00374231,-0.01047798,0.01042156,0.04570435,0.02338702,-0.01205241,-0.00024124,-0.06454246,-0.01621804,-0.02878775,-0.02299258,-0.02228763,0.02072081,0.0412494,-0.00360512,-0.02136329,-0.29374185,0.04174737,0.07370807,-0.00064768,-0.07756048,0.05567603,0.02952433,-0.03732786,-0.03003975,0.01735664,-0.07684781,0.08934686,0.02958913,-0.00364029,0.04741945,0.02372844,0.02435544,-0.03525826,0.01592959,0.02133377,-0.07102359,0.01116427,0.19622071,-0.00416097,0.04652386,-0.06487145,-0.03675546,0.03612633,0.05659576,0.02329928,-0.01815735,0.00844839,0.09006305,-0.06569292,0.02759175,0.08352512,-0.03080477,0.02141608,0.01007626,0.0242513,0.04372073,0.02120588,-0.00001069,-0.02363017,0.10308277,0.02491469,-0.03284375,-0.03444031,-0.03603533,-0.03069809,-0.02027581,0.05012623,0.02897702,0.04120119,0.04487641,0.06562044,-0.01313794,-0.00471685,-0.04980725,0.03125817,0.01448793,-0.03501062,0.00738642,0.00695406,0.01415162],"last_embed":{"hash":"12vafyl","tokens":96}}},"text":null,"length":0,"last_read":{"hash":"12vafyl","at":1770290020318},"key":"Transformers/Multi-Head Attention.md##2. The Math of Multi-Head Attention#Step D: Final Linear Projection","lines":[52,57],"size":227,"outlinks":[],"class_name":"SmartBlock","last_embed":{"hash":"12vafyl","at":1770290020318}},
"smart_blocks:Transformers/Multi-Head Attention.md##Summary": {"path":null,"embeddings":{"TaylorAI/bge-micro-v2":{"vec":[-0.02474873,-0.03543393,0.02326586,-0.05820575,-0.07445672,0.03495038,-0.0577998,-0.00309648,0.05909291,0.03225585,0.03511129,-0.07184795,0.04238133,0.06106238,0.05793009,0.02808482,-0.04515824,0.02220475,-0.07016107,-0.02883857,0.01856555,0.02703439,-0.05145074,-0.01193036,0.0407135,0.02540982,-0.01722373,-0.11059743,-0.03345313,-0.26102665,0.05492859,0.06986811,0.06054677,-0.00201013,-0.04881971,-0.05592098,-0.00734476,0.02864138,-0.02640053,0.04416588,0.01095306,-0.02796811,-0.03368283,-0.0680516,-0.05565149,-0.04406748,-0.07329153,-0.00168773,-0.00955497,-0.03407484,-0.03725291,-0.04531634,0.01290474,0.0334546,0.05337329,0.03372177,0.00901412,0.04744675,0.0383552,0.05375686,0.03391146,0.0710258,-0.11238671,0.0827683,0.07388695,-0.01919291,-0.0795358,0.00045263,-0.01633713,0.10751587,-0.0343697,-0.0224382,0.02426765,-0.00263824,0.03451952,-0.00611437,-0.01177467,0.00042977,0.02788652,0.03248107,-0.00561359,0.00404685,0.0033292,0.00413227,-0.0224485,0.05794321,-0.01966151,-0.02787251,-0.02693738,0.0038789,-0.03573284,-0.02721474,0.00323801,-0.03353606,-0.03108449,-0.02245769,0.03949173,-0.00246813,-0.00636456,0.11078947,-0.03428955,-0.00323832,0.06579955,-0.05947944,-0.00983065,-0.02615237,-0.0026411,-0.00514259,-0.05646485,-0.02676411,-0.03373951,-0.03945476,-0.01196609,-0.02516483,0.01882927,0.02040994,0.04691558,0.05324369,0.01080964,-0.06769437,0.03190327,-0.004457,0.03509661,0.01642974,0.0365134,-0.0184586,0.08197941,0.08632745,0.00953214,0.06555091,0.07569169,0.08159711,-0.0443588,-0.00686517,-0.01063858,0.00534006,0.04157717,-0.00824286,0.0148865,0.03131599,0.00791259,0.00567777,0.01259789,-0.06695843,0.00004701,0.15751733,-0.06779227,-0.04354877,-0.04324918,-0.01420777,-0.07014009,0.04531458,-0.01695585,-0.02748113,0.00748403,0.01246891,0.04257891,-0.02847271,-0.08238383,0.05057557,-0.06449623,-0.04922739,-0.04103357,0.15691093,0.02521711,-0.1003237,-0.03070213,-0.0142317,0.01418308,-0.06515816,0.02344877,0.01114011,0.0112694,0.01224103,0.0166629,0.02417848,-0.12218871,-0.01726175,0.02581223,-0.0116077,0.0318679,-0.04496814,-0.01661069,0.01264182,0.02062446,-0.03513888,0.00674078,-0.00733665,-0.05037533,0.04669072,-0.12440048,-0.03649003,-0.01318945,0.04407725,-0.01856136,-0.02843777,0.01469382,-0.02598305,0.01419251,-0.0266579,0.03544511,-0.02113283,-0.05945564,-0.01872226,-0.02048793,0.04610761,-0.00552209,-0.01394866,0.05391654,0.08883274,-0.04006345,0.01593022,0.08682885,-0.0244432,-0.01225962,-0.05048645,0.01404544,0.06822195,-0.02346608,0.03751611,0.01101089,-0.05489102,-0.04548554,-0.1903079,-0.03157831,0.09040061,-0.01712707,0.05304527,-0.07119113,0.0240666,0.02890411,-0.02039243,0.08611076,0.09831896,0.04169205,-0.06489068,-0.02485564,-0.02021197,0.00612948,0.04866082,0.01858288,-0.044424,0.0192156,0.00593167,0.04130423,0.05009485,-0.07154819,0.05737243,-0.0368458,0.16593033,0.02779139,0.08688489,0.05516455,0.04979482,0.04814513,-0.02889413,-0.02048863,0.01924372,0.00047767,0.03131487,0.00967803,0.01083855,-0.05034091,-0.07410571,-0.03180492,-0.00603232,-0.09775648,0.06652045,-0.01276375,-0.07120112,-0.04174713,-0.00176341,-0.01115916,0.05872098,-0.11076995,-0.00887841,0.03248661,0.00078937,0.0080227,-0.05518193,-0.0140928,-0.07377318,0.00960663,0.01781171,-0.02749163,0.00661895,-0.04537693,0.03612184,0.05686677,-0.00958217,0.0246207,-0.03497548,-0.01287507,-0.02454508,0.02529849,0.05076604,0.06298614,-0.02226741,0.02411294,-0.0083763,0.00084561,-0.03770021,0.04062075,0.04913695,-0.07896017,0.01255821,0.01107212,0.04686843,0.01838298,0.0275667,-0.05147193,0.04586979,-0.03854746,-0.01202919,-0.00403513,-0.04034488,0.06314259,0.04956865,-0.05243356,-0.26072732,0.04011736,0.09017562,0.00957449,-0.05563008,0.05812497,0.04950142,-0.08704052,-0.00876941,0.03511327,-0.02559818,0.07524984,0.03737095,0.00807695,0.00362309,0.05731011,0.05110903,-0.02282258,0.03286781,-0.02260453,-0.01458074,0.03327686,0.18846363,-0.02583875,0.03656509,-0.01442343,-0.05005272,-0.01886729,0.05198225,0.03395599,0.00229245,-0.0135732,0.0663883,-0.06359909,0.04237051,0.0619843,-0.01309403,0.02249566,0.03357242,0.05753878,-0.03310862,-0.01680368,-0.00275935,-0.04743955,0.04509193,-0.00738828,-0.02336969,-0.01609795,-0.06556156,-0.00378452,0.01788091,0.03317446,0.06056346,-0.00573714,0.03784477,0.06346777,-0.02313228,-0.01462403,-0.04341488,0.02905037,0.04286943,-0.0860689,0.02081409,0.0182709,-0.02559717],"last_embed":{"hash":"9zk91g","tokens":131}}},"text":null,"length":0,"last_read":{"hash":"9zk91g","at":1770290020354},"key":"Transformers/Multi-Head Attention.md##Summary","lines":[58,67],"size":440,"outlinks":[{"title":"Feed-Forward Networks","target":"Feed-Forward Networks","line":9},{"title":"Positional Encoding","target":"Positional Encoding","line":9}],"class_name":"SmartBlock","last_embed":{"hash":"9zk91g","at":1770290020354}},
